{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "# This notebook is an example to determine which sentence is positive, and also show\n",
    "# the usage of Keras embedding layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Flatten\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "        'Very nice',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = np.array([1,1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "tk = Tokenizer(oov_token='UNK')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "{1: 'UNK',\n 2: 'work',\n 3: 'done',\n 4: 'good',\n 5: 'nice',\n 6: 'effort',\n 7: 'poor',\n 8: 'well',\n 9: 'very',\n 10: 'great',\n 11: 'excellent',\n 12: 'weak',\n 13: 'not',\n 14: 'could',\n 15: 'have',\n 16: 'better'}"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.fit_on_texts(docs)\n",
    "tk.index_word"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "[[8, 3],\n [4, 2],\n [9, 5],\n [10, 6],\n [5, 2],\n [11],\n [12],\n [7, 6],\n [13, 4],\n [7, 2],\n [14, 15, 3, 16]]"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_docs = tk.texts_to_sequences(docs)\n",
    "encoded_docs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  3  0  0]\n",
      " [ 4  2  0  0]\n",
      " [ 9  5  0  0]\n",
      " [10  6  0  0]\n",
      " [ 5  2  0  0]\n",
      " [11  0  0  0]\n",
      " [12  0  0  0]\n",
      " [ 7  6  0  0]\n",
      " [13  4  0  0]\n",
      " [ 7  2  0  0]\n",
      " [14 15  3 16]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 4, 8)              136       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 169\n",
      "Trainable params: 169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "\n",
    "# the index of input starts from 0 in Keras embedding layer\n",
    "vocab_size = len(tk.index_word) + 1\n",
    "\n",
    "model = Sequential()\n",
    "embed = Embedding(vocab_size, output_dim=8, input_length=max_length)\n",
    "model.add(embed)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6917 - accuracy: 0.4545\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6899 - accuracy: 0.5455\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.6881 - accuracy: 0.5455\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6864 - accuracy: 0.5455\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6846 - accuracy: 0.6364\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 182us/step - loss: 0.6828 - accuracy: 0.6364\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6810 - accuracy: 0.6364\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 91us/step - loss: 0.6793 - accuracy: 0.6364\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 91us/step - loss: 0.6775 - accuracy: 0.6364\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6758 - accuracy: 0.6364\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6740 - accuracy: 0.6364\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6723 - accuracy: 0.6364\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 91us/step - loss: 0.6705 - accuracy: 0.6364\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6688 - accuracy: 0.6364\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6670 - accuracy: 0.6364\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6653 - accuracy: 0.6364\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 91us/step - loss: 0.6636 - accuracy: 0.6364\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6618 - accuracy: 0.6364\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6601 - accuracy: 0.6364\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6583 - accuracy: 0.6364\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6566 - accuracy: 0.6364\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6548 - accuracy: 0.6364\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6531 - accuracy: 0.6364\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6513 - accuracy: 0.7273\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6496 - accuracy: 0.7273\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 91us/step - loss: 0.6478 - accuracy: 0.7273\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6460 - accuracy: 0.7273\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6443 - accuracy: 0.7273\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6425 - accuracy: 0.7273\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 91us/step - loss: 0.6407 - accuracy: 0.7273\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6389 - accuracy: 0.7273\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6371 - accuracy: 0.7273\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6353 - accuracy: 0.7273\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6335 - accuracy: 0.7273\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6317 - accuracy: 0.7273\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.6299 - accuracy: 0.7273\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.6281 - accuracy: 0.7273\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.6263 - accuracy: 0.7273\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 182us/step - loss: 0.6245 - accuracy: 0.7273\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6226 - accuracy: 0.7273\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6208 - accuracy: 0.7273\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6190 - accuracy: 0.7273\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6171 - accuracy: 0.7273\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 91us/step - loss: 0.6152 - accuracy: 0.7273\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 181us/step - loss: 0.6134 - accuracy: 0.7273\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.6115 - accuracy: 0.7273\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.6096 - accuracy: 0.7273\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.6077 - accuracy: 0.7273\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 182us/step - loss: 0.6059 - accuracy: 0.7273\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 272us/step - loss: 0.6040 - accuracy: 0.7273\n",
      "Accuracy: 72.727275\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=1)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "[[9, 4], [9, 7]]"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_docs = ['very good',\n",
    "\t\t     'very poor']\n",
    "\n",
    "test_encoded_docs = tk.texts_to_sequences(test_docs)\n",
    "test_encoded_docs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 4 0 0]\n",
      " [9 7 0 0]]\n"
     ]
    }
   ],
   "source": [
    "test_padded_docs = pad_sequences(test_encoded_docs, maxlen=max_length, padding='post')\n",
    "print(test_padded_docs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.55882627],\n       [0.57063407]], dtype=float32)"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_padded_docs)\n",
    "y_pred\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([[-2.8333687e-03, -3.3480845e-02,  5.5552438e-02, -5.4558508e-02,\n         -4.2722899e-02, -2.3858266e-02, -6.0415097e-02, -6.7735694e-02],\n        [ 2.5708426e-02,  1.7102096e-02, -3.8722903e-04,  2.5692847e-02,\n          1.1156999e-02, -7.1636215e-03,  7.6245442e-03,  3.9116964e-03],\n        [ 2.1070907e-02,  3.1960603e-02,  6.6141345e-02, -4.2721730e-02,\n         -8.4666803e-02,  7.7068023e-02, -6.7876622e-02,  7.0303731e-02],\n        [ 6.5865941e-02,  6.9620982e-02,  6.6943698e-02, -3.2968737e-02,\n         -7.6907150e-02,  2.2538776e-02,  3.6535215e-02,  9.5670037e-02],\n        [ 2.5622102e-02, -5.4880779e-02,  7.3884182e-02,  4.0044077e-05,\n          6.1757363e-02, -2.7064726e-02,  1.7423810e-02, -5.9651185e-02],\n        [ 1.7818743e-02, -6.3986517e-02,  6.8396576e-02, -2.4390290e-02,\n         -9.1411725e-02,  4.1740272e-02, -5.9658948e-02, -9.7657725e-02],\n        [-7.0328131e-02, -6.8728991e-02, -1.0117333e-01,  2.6476542e-02,\n          9.6251450e-02, -8.5902726e-03,  8.4688671e-02, -5.1403549e-02],\n        [-5.4816894e-02,  4.8353124e-02, -1.6054947e-02,  3.3131722e-02,\n          7.3629998e-02,  5.9966478e-02, -1.2817688e-02,  4.2076074e-02],\n        [ 9.7251505e-02, -6.1039347e-02,  5.1514246e-03, -1.5992913e-02,\n         -1.1996573e-02, -8.9185640e-02,  5.2490536e-02, -6.5883122e-02],\n        [ 1.0370986e-02, -3.3793725e-02,  5.5934064e-02, -5.9128247e-02,\n         -6.8039678e-02, -6.3109659e-02,  7.5921607e-03, -5.2192252e-02],\n        [ 9.4757341e-02, -6.9765247e-02,  7.4277453e-02, -2.9328736e-02,\n         -9.1541655e-02, -8.8466719e-02,  6.5700963e-02, -1.6632060e-02],\n        [ 4.7773728e-03, -7.7669874e-02,  2.2716992e-02, -3.5318431e-02,\n         -2.7066011e-02, -1.5762338e-02,  8.1523813e-02, -2.0669952e-02],\n        [-9.2095420e-02,  3.7735317e-02, -1.8393658e-02,  6.6537492e-02,\n          7.5686730e-02,  1.9790610e-02, -7.3219791e-02,  8.9843385e-02],\n        [-2.3832904e-02,  8.1654280e-02, -7.9188112e-04,  3.3748928e-02,\n          8.7898232e-02,  6.7741685e-02, -4.8815530e-02,  5.0210372e-02],\n        [-8.6564347e-02,  5.5314239e-02, -1.8257719e-02,  3.3881307e-02,\n          7.7730477e-02,  5.4963902e-02, -8.6123422e-02,  9.0749890e-02],\n        [-5.8149427e-02, -7.1758233e-02, -5.3706919e-03,  2.2855455e-02,\n          2.8604511e-02, -8.1520222e-02,  1.6399575e-02, -3.6470550e-03],\n        [ 6.7963094e-02, -8.5809045e-03, -9.7462572e-02,  8.2682379e-02,\n         -3.7542053e-02,  9.2105284e-02,  3.9864782e-02,  1.7360933e-03]],\n       dtype=float32)]"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.get_weights()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 8)\n"
     ]
    }
   ],
   "source": [
    "# embedding layer is a matrix with vocab_size rows and output_dim columns\n",
    "print(embed.get_weights()[0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}